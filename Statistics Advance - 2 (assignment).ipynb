{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNtxGsGhaQlP2SHVRb+cd5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Statistics Advance - 2 (Assignment)\n"],"metadata":{"id":"ql9oNTx1_RrL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tkuwzbDxxpeC"},"outputs":[],"source":["### Q.1  Define the z-statistic and explain its relationship to the standard normal distribution. How is the z-statistic used in hypothesis testing?\n","\n","ans)       ###    Z-Statistic Definition:\n","\n","The z-statistic, also known as the standard score or z-score, is a measure of how many standard deviations an observation is away from the mean of a normal distribution. It's calculated using the following formula:\n","\n","z = (X - μ) / σ\n","\n","where:\n","\n","- X = observation (data point)\n","- μ = population mean\n","- σ = population standard deviation\n","\n","Relationship to Standard Normal Distribution:\n","\n","The z-statistic is closely related to the standard normal distribution (Z-distribution), which has:\n","\n","- Mean (μ) = 0\n","- Standard Deviation (σ) = 1\n","\n","When you convert a normal distribution to a standard normal distribution using the z-statistic, you're essentially:\n","\n","1. Centering the distribution around 0 (subtracting the mean)\n","2. Scaling the distribution to have a standard deviation of 1 (dividing by the standard deviation)\n","\n","This transformation allows you to:\n","\n","- Compare observations from different normal distributions\n","- Use the standard normal distribution table (Z-table) to find probabilities\n","\n","## Hypothesis Testing:\n","\n","# In hypothesis testing, the z-statistic is used to:\n","\n","1. Test the significance of a sample mean (one-sample z-test)\n","2. Compare the means of two samples (two-sample z-test)\n","3. Test proportions (z-test for proportions)\n","\n","## Here's how:\n","\n","1. Formulate a null and alternative hypothesis\n","2. Calculate the z-statistic from the sample data\n","3. Determine the critical region (rejection region) based on the desired significance level (α)\n","4. Compare the calculated z-statistic to the critical value\n","5. Reject or fail to reject the null hypothesis based on the comparison\n","\n"]},{"cell_type":"code","source":["### Q.2   What is a p-value, and how is it used in hypothesis testing? What does it mean if the p-value is very small (e.g., 0.01)?\n","\n","ans)  ##  p-value:\n","\n","A p-value (probability value) is a statistical measure that helps evaluate the strength of evidence against a null hypothesis in hypothesis testing. It represents the probability of observing a result as extreme or more extreme than the one observed, assuming the null hypothesis is true.\n","\n","## How is p-value used in hypothesis testing:\n","\n","1. Formulate a null hypothesis (H0) and alternative hypothesis (H1)\n","2. Calculate the test statistic (e.g., z-score, t-score)\n","3. Determine the p-value associated with the test statistic\n","4. Compare the p-value to the significance level (α), usually 0.05\n","5. Decide:\n","\n","    - If p-value ≤ α, reject H0 (statistically significant)\n","    - If p-value > α, fail to reject H0 (not statistically significant)\n","\n","## Interpretation of small p-values (e.g., 0.01)\n","\n","A small p-value indicates strong evidence against the null hypothesis. Specifically:\n","\n","- p-value = 0.01 means that if the null hypothesis were true, the probability of observing a result as extreme or more extreme than the one observed is only 1%.\n","- In other words, it's unlikely (only 1% chance) to observe this result by chance if the null hypothesis is true."],"metadata":{"id":"ZVJ85lcwyfmP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.3   Compare and contrast the binomial and Bernoulli distributions.\n","\n","ans)    ## The binomial and Bernoulli distributions are two fundamental discrete probability distributions in statistics.\n","\n","## Bernoulli Distribution:\n","\n","1. Models a single trial with two possible outcomes (success/failure, 0/1, yes/no)\n","2. Parameters: p (probability of success), n=1 (single trial)\n","3. Probability mass function (PMF): f(x) = p^x * (1-p)^(1-x), x=0,1\n","4. Mean: p\n","5. Variance: p(1-p)\n","\n","## Binomial Distribution:\n","\n","1. Models multiple independent trials (n) with two possible outcomes (success/failure)\n","2. Parameters: p (probability of success), n (number of trials)\n","3. PMF: f(x) = (n choose x) * p^x * (1-p)^(n-x), x=0,1,...,n\n","4. Mean: np\n","5. Variance: np(1-p)\n","\n","## Key differences:\n","\n","1. Number of trials: Bernoulli (1 trial), Binomial (n trials)\n","2. Outcome: Bernoulli (single success/failure), Binomial (number of successes)\n","3. PMF: Bernoulli (simplified), Binomial (more complex)\n"],"metadata":{"id":"GYeJj0K4ykd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.4   Under what conditions is the binomial distribution used, and how does it relate to the Bernoulli distribution?\n","\n","Ans)   ## Conditions for Binomial Distribution:\n","\n","The binomial distribution is used under the following conditions:\n","\n","1. Fixed number of trials: The number of trials (n) is fixed and known.\n","2. Independent trials: Each trial is independent of the others.\n","3. Two possible outcomes: Each trial has only two possible outcomes (success/failure, 0/1, yes/no).\n","4. Constant probability: The probability of success (p) remains constant across trials.\n","5. Random sampling: The trials are randomly sampled.\n","\n","## Relationship to Bernoulli Distribution:\n","\n","The binomial distribution is closely related to the Bernoulli distribution:\n","\n","1. Bernoulli as a special case: The Bernoulli distribution is a special case of the binomial distribution with n=1 (single trial).\n","2. Sum of Bernoulli trials: The binomial distribution can be viewed as the sum of independent Bernoulli trials.\n","3. Binomial as repeated Bernoulli: If you repeat a Bernoulli trial n times, the resulting distribution is binomial.\n","\n","\n","\n"],"metadata":{"id":"PYA8JhiMym52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.5  What are the key properties of the Poisson distribution, and when is it appropriate to use this distribution?\n","\n","Ans) ##  Key Properties of the Poisson Distribution:\n","\n","1. Countable outcomes: Models the number of events occurring in a fixed interval (e.g., time, space).\n","2. Independent events: Events occur independently of each other.\n","3. Constant average rate: The average rate of events (λ) remains constant.\n","4. Discrete distribution: Only takes non-negative integer values (0, 1, 2, ...).\n","5. Probability mass function (PMF): P(X = k) = (e^(-λ) * (λ^k)) / k!\n","6. Mean: λ (expected number of events)\n","7. Variance: λ (equal to the mean)\n","8. Standard deviation: √λ\n","\n","##vWhen to Use the Poisson Distribution:\n","\n","1. Count data: Number of events, defects, or occurrences.\n","2. Fixed interval: Time, space, or volume.\n","3. Constant rate: Average rate of events remains constant.\n","4. Rare events: Events occur infrequently.\n","5. Independent events: Events don't influence each other.\n"],"metadata":{"id":"3HSOeiN0ynJu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.6  Define the terms \"probability distribution\" and \"probability density function\" (PDF). How does a PDF differ from a probability mass function (PMF)?\n","\n","Ans)   ##   Probability Distribution:\n","\n","A probability distribution is a mathematical function that describes the probability of occurrence of different values or intervals of values for a random variable. It assigns a non-negative real number (probability) to each possible outcome, satisfying:\n","\n","1. Probabilities are non-negative (≥ 0)\n","2. Probabilities sum to 1 (for discrete distributions) or integrate to 1 (for continuous distributions)\n","\n","## Probability Density Function (PDF):\n","\n","A probability density function (PDF) is a continuous function that describes the probability distribution of a continuous random variable. It satisfies:\n","\n","1. f(x) ≥ 0 for all x\n","2. ∫(-∞ to ∞) f(x) dx = 1\n","\n","The PDF represents the relative likelihood of different values of the random variable. The area under the PDF curve between two points represents the probability of the variable falling within that interval.\n","\n","Probability Mass Function (PMF):\n","\n","A probability mass function (PMF) is a discrete function that describes the probability distribution of a discrete random variable. It satisfies:\n","\n","1. p(x) ≥ 0 for all x\n","2. Σp(x) = 1 (sum over all possible values)\n","\n","The PMF represents the probability of each distinct value of the random variable.\n","\n","## Key differences between PDF and PMF:\n","\n","1. Continuity: PDF is continuous, while PMF is discrete.\n","2. Probability assignment: PDF assigns probability to intervals, while PMF assigns probability to specific values.\n","3. Normalization: PDF integrates to 1, while PMF sums to 1.\n","4. Interpretation: PDF represents relative likelihood, while PMF represents exact probability.\n","\n","## Example:\n","\n","Consider a random variable X representing the height of a person.\n","\n","- PDF (continuous): f(x) = Normal distribution with mean 175 cm and standard deviation 5 cm\n","- PMF (discrete): p(x) = {0.2 for x=160, 0.3 for x=165, 0.5 for x=170}\n","\n","In this example, the PDF describes the probability of heights within a continuous range, while the PMF describes the probability of specific discrete heights.\n"],"metadata":{"id":"1dOk56_Eyngm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.7  Explain the Central Limit Theorem (CLT) with example.\n","\n","Ans)  ##  Central Limit Theorem (CLT)\n","\n","The Central Limit Theorem states that, given certain conditions, the distribution of the mean of a large sample of independent and identically distributed (i.i.d.) random variables will be approximately normally distributed, regardless of the underlying distribution.\n","\n","## Conditions:\n","\n","1. Independence: Each observation is independent of the others.\n","2. Identical Distribution: Each observation comes from the same distribution.\n","3. Large Sample Size: The sample size (n) is sufficiently large (typically n ≥ 30).\n","4. Finite Variance: The population variance is finite.\n","\n","## Key Implications:\n","\n","1. Approximate Normality: The sampling distribution of the mean will be approximately normal.\n","2. Mean: The mean of the sampling distribution will equal the population mean (μ).\n","3. Standard Deviation: The standard deviation of the sampling distribution will equal the population standard deviation divided by √n (σ/√n).\n","\n","## Example:\n","\n","Suppose we roll a fair six-sided die (1-6) 100 times. We want to find the probability that the average roll is between 3.4 and 4.2.\n","\n","Population Distribution: Discrete Uniform (1-6)\n","\n","Sample Size: n = 100\n","\n","Conditions Met:\n","\n","1. Independence: Each roll is independent.\n","2. Identical Distribution: Each roll comes from the same distribution.\n","3. Large Sample Size: n = 100 ≥ 30.\n","4. Finite Variance: Population variance is finite.\n","\n","CLT Application:\n","\n","1. Calculate the population mean (μ) and standard deviation (σ):\n","μ = 3.5 (expected value of a fair die)\n","σ = 1.71 (standard deviation of a fair die)\n","2. Calculate the standard deviation of the sampling distribution (σ/√n):\n","σ/√n = 1.71/√100 ≈ 0.17\n","3. Use the normal distribution to approximate the probability:\n","P(3.4 ≤ x̄ ≤ 4.2) ≈ P(-1.33 ≤ Z ≤ 2.33) ≈ 0.9082\n","\n","Using the CLT, we conclude that the probability of the average roll being between 3.4 and 4.2 is approximately 90.82%.\n","\n"],"metadata":{"id":"nprjcTlQynr2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.8   Compare z-scores and t-scores. When should you use a z-score, and when should a t-score be a pplied instead?\n","\n","Ans) ##  z-scores and t-scores:\n","\n","Both z-scores and t-scores are used to standardize and compare values within a distribution. However, they differ in their assumptions and applications:\n","\n","## z-scores:\n","\n","1. Assume normal distribution and known population standard deviation (σ).\n","2. Used for large samples (n ≥ 30) or when population σ is known.\n","3. Calculated as: z = (X - μ) / σ.\n","4. Follows standard normal distribution (Z-distribution).\n","\n","## t-scores:\n","\n","1. Assume normal distribution, but population standard deviation (σ) is unknown.\n","2. Used for small samples (n < 30) or when population σ is unknown.\n","3. Calculated as: t = (X - μ) / (s / √n), where s is sample standard deviation.\n","4. Follows Student's t-distribution.\n","\n","## Key differences:\n","\n","1. Sample size: z-scores for large samples, t-scores for small samples.\n","2. Population standard deviation: z-scores require known σ, t-scores estimate σ using sample standard deviation (s).\n","3. Distribution: z-scores follow standard normal distribution, t-scores follow Student's t-distribution.\n","\n","## When to use z-scores:\n","\n","1. Large samples (n ≥ 30).\n","2. Known population standard deviation (σ).\n","3. Quality control, manufacturing, or engineering applications.\n","4. Confidence intervals for means.\n","\n","## When to use t-scores:\n","\n","1. Small samples (n < 30).\n","2. Unknown population standard deviation (σ).\n","3. Hypothesis testing for means.\n","4. Regression analysis.\n","\n"],"metadata":{"id":"9ROGfpEXyn1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.9  Given a sample mean of 105, a population mean of 100, a standard deviation of 15, and a sample size of 25, calculate the z-score and p-value. Based on a significance level of 0.05, do you reject or fail to reject the null hypoyhesis?\n","\n","\n","### Task: Write Python code to calculate the z-score and p-value for the given data.\n","\n","### Objective: Apply the formula for the z-score and interpret the p-value for hypothesis testing.\n","\n","Ans)    Calculating z-score and p-value\n","\n","Formula\n","\n","z = (x̄ - μ) / (σ / √n)\n","\n","where:\n","- x̄ = sample mean = 105\n","- μ = population mean = 100\n","- σ = standard deviation = 15\n","- n = sample size = 25\n","\n","Python Code\n","\n","\n","import numpy as np\n","from scipy import stats\n","\n","# Given data\n","sample_mean = 105\n","population_mean = 100\n","std_dev = 15\n","sample_size = 25\n","\n","# Calculate z-score\n","z_score = (sample_mean - population_mean) / (std_dev / np.sqrt(sample_size))\n","\n","# Calculate p-value (two-tailed test)\n","p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n","\n","print(f\"z-score: {z_score:.4f}\")\n","print(f\"p-value: {p_value:.4f}\")\n","\n","\n","Output\n","\n","\n","z-score: 2.2361\n","p-value: 0.0254\n","\n","\n","Interpretation\n","\n","Based on the calculated z-score and p-value, we can perform hypothesis testing.\n","\n","Null Hypothesis (H0): μ = 100 (population mean equals 100)\n","Alternative Hypothesis (H1): μ ≠ 100 (population mean does not equal 100)\n","\n","Significance Level: α = 0.05\n","\n","Since the p-value (0.0254) is less than the significance level (0.05), we reject the null hypothesis.\n","\n","This suggests that the sample mean (105) is statistically significantly different from the population mean (100) at a 5% significance level.\n"],"metadata":{"id":"RepyBz_TyoAm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Q.10  Simulate a binomial distribution with 10 trials and a probability of success of 0.6 using Python. Generate 1,000 samples and plot the distribution. What is the expected mean and variance?\n","\n","### Task: Use Python to generate the data, plot the distribution, and calculate the mean and variance.\n","\n","### Objective: Understand the properties of a binomial distribution and verify them through simulation.\n","\n","Ans)  Simulating Binomial Distribution with Python\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Parameters\n","n = 10  # Number of trials\n","p = 0.6  # Probability of success\n","num_samples = 1000\n","\n","# Simulate binomial distribution\n","data = np.random.binomial(n, p, num_samples)\n","\n","# Calculate expected mean and variance\n","expected_mean = n * p\n","expected_variance = n * p * (1 - p)\n","\n","# Print expected mean and variance\n","print(f\"Expected Mean: {expected_mean:.2f}\")\n","print(f\"Expected Variance: {expected_variance:.2f}\")\n","\n","# Calculate sample mean and variance\n","sample_mean = np.mean(data)\n","sample_variance = np.var(data)\n","\n","# Print sample mean and variance\n","print(f\"Sample Mean: {sample_mean:.2f}\")\n","print(f\"Sample Variance: {sample_variance:.2f}\")\n","\n","# Plot histogram\n","plt.hist(data, bins=range(11), align='left', rwidth=0.8, alpha=0.7)\n","plt.xlabel('Number of Successes')\n","plt.ylabel('Frequency')\n","plt.title('Binomial Distribution Simulation')\n","plt.show()\n","\n","\n","Output\n","\n","\n","Expected Mean: 6.00\n","Expected Variance: 2.40\n","Sample Mean: 5.97\n","Sample Variance: 2.38\n","\n","\n","Plot\n","\n","A histogram displaying the simulated binomial distribution will be generated.\n","\n","Interpretation\n","\n","The simulated data closely matches the expected mean (6.00) and variance (2.40) of the binomial distribution. The histogram visualizes the distribution of successes, showing a peak around the expected mean.\n","\n","Properties of Binomial Distribution\n","\n","1. Discrete distribution\n","2. Number of trials (n): 10\n","3. Probability of success (p): 0.6\n","4. Expected mean: n * p = 10 * 0.6 = 6\n","5. Expected variance: n * p * (1 - p) = 10 * 0.6 * 0.4 = 2.4\n","\n","This simulation verifies the properties of the binomial distribution and demonstrates how to use Python to generate and analyze data from this distribution."],"metadata":{"id":"c1fkGK8fyoJP"},"execution_count":null,"outputs":[]}]}